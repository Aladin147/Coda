# Coda Default Configuration
# This is the base configuration for Coda 2.0

# Voice processing configuration
voice:
  stt:
    engine: "whisper"  # Options: whisper, kyutai (future)
    model: "base"      # Options: tiny, base, small, medium, large
    device: "cuda"     # Options: cpu, cuda
    compute_type: "float16"  # Options: float32, float16, int8
    language: "en"     # Language code or null for auto-detection
    vad_filter: true   # Voice Activity Detection
  
  tts:
    engine: "elevenlabs"  # Options: elevenlabs, kyutai (future)
    voice_id: "21m00Tcm4TlvDq8ikWAM"  # ElevenLabs voice ID
    model_id: "eleven_multilingual_v2"
    stability: 0.5
    similarity_boost: 0.75
    style: 0.0
    use_speaker_boost: true

# Memory system configuration
memory:
  short_term:
    max_turns: 20      # Maximum conversation turns to keep
    max_tokens: 800    # Maximum tokens for context
  
  long_term:
    enabled: true      # Enable long-term memory
    path: "data/memory/long_term"
    vector_db: "chroma"  # Options: chroma, sqlite, in_memory
    embedding_model: "all-MiniLM-L6-v2"
    max_memories: 1000
    device: "cpu"      # Device for embedding model
    
    # Memory encoding settings
    chunk_size: 200
    chunk_overlap: 50
    min_chunk_length: 50
    
    # Persistence settings
    auto_persist: true
    persist_interval: 5

# Personality engine configuration
personality:
  base_personality: "helpful"  # Base personality type
  adaptation_enabled: true     # Enable learning from feedback
  learning_rate: 0.1          # How quickly to adapt
  lore_file: "configs/personality/lore.json"
  
  # Advanced features
  behavioral_conditioning: true
  topic_awareness: true
  session_management: true

# Tool system configuration
tools:
  enabled: true
  available_tools:
    - "get_time"
    - "get_date"
    - "tell_joke"
    - "get_weather"
    - "search_memory"
    - "add_memory"
    - "list_tools"
    - "show_capabilities"

# Language model configuration
llm:
  model_name: "llama3"
  host: "http://localhost:11434"
  timeout: 120
  temperature: 0.7
  max_tokens: 256

# Intent routing configuration
intent:
  enabled: true
  debug_mode: false

# Feedback system configuration
feedback:
  enabled: true
  frequency: 0.3     # How often to request feedback (0.0 to 1.0)
  cooldown: 5        # Minimum turns between feedback requests
  apply_adjustments: true

# Audio settings
audio:
  input_device: null   # null = default device
  output_device: null  # null = default device
  sample_rate: 16000
  channels: 1

# WebSocket dashboard configuration
dashboard:
  enabled: false
  host: "localhost"
  port: 8765
  cors_origins:
    - "http://localhost:3000"
    - "http://localhost:8080"

# Logging configuration
logging:
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  file: "logs/coda.log"
  max_size: 10485760  # 10 MB
  backup_count: 5
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Performance settings
performance:
  max_concurrent_users: 1  # Will increase with Kyutai integration
  response_timeout: 30     # Maximum response time in seconds
  memory_cleanup_interval: 300  # Memory cleanup interval in seconds

# Development settings (only used in dev mode)
development:
  debug_mode: false
  mock_services: false
  test_data_path: "tests/data"
  profiling_enabled: false

# Production settings
production:
  monitoring_enabled: false
  metrics_endpoint: "/metrics"
  health_check_endpoint: "/health"
  graceful_shutdown_timeout: 30
